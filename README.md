# LLM-Reasoning-and-SelfEvaluating
This is a curated list of "LLM Reasoning and SelfEvaluating" research. Read this repository for the latest updates. Feel free to raise pull requests and launch the discussion!

## NLP Evaluation Survey
- [zhihu](https://zhuanlan.zhihu.com/p/644373658)

## Can 
- PROMPTAGENT: STRATEGIC PLANNING WITH LANGUAGE MODELS ENABLES EXPERT-LEVEL PROMPT OPTIMIZATION
- LARGE LANGUAGE MODELS AS OPTIMIZERS (Use labeld feedback)
- Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency
- CRITIC: LARGE LANGUAGE MODELS CAN SELFCORRECT WITH TOOL-INTERACTIVE CRITIQUING (Use tool feedback)


## Cannot 
- Large Language Models Cannot Self-Correct Reasoning Yet [1st]
- GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems
- Can Large Language Models Really Improve by Self-critiquing Their Own Plans?
- Language Models (Mostly) Know What They Know [1st]
- Benchmarking Foundation Models with Language-Model-as-an-Examiner.
- PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization
- Large Language Models are not Fair Evaluator



## Method Design
- EVALUATING LARGE LANGUAGE MODELS AT EVALUATING INSTRUCTION FOLLOWING (Chen Danqi)
- [Eliciting Human Preferences with Language Models](https://arxiv.org/abs/2310.11589)
